{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "\n",
    "#Split Training and Test Set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.093567251462\n",
      "Time it takes to fit and predict XGB \t0.0596899986267\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier()\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with max_depth parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.093567251462\n",
      "Time it takes to fit and predict XGB \t0.0311439037323\n",
      "Less accurate; the time is about the same.\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier(max_depth = 2)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)\n",
    "print \"Less accurate; the time is about the same.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with n_estimators parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.00584795321637\n",
      "Time it takes to fit and predict XGB \t0.00474500656128\n",
      "More accurate; Less time when 0 < n_estimators < 7.\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier(n_estimators=3)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)\n",
    "print \"More accurate; Less time when 0 < n_estimators < 7.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with nthread parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.093567251462\n",
      "Time it takes to fit and predict XGB \t0.0279731750488\n",
      "Accuracy remains the same as the original; More time if int is higher, and less time if int is smaller.\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier(nthread=3)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)\n",
    "print \"Accuracy remains the same as the original; More time if int is higher, and less time if int is smaller.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with gamma parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.093567251462\n",
      "Time it takes to fit and predict XGB \t0.0263950824738\n",
      "More accurate when the float is .1 and less so when it's higher; time is faster than original regardless of float.\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier(gamma = .1)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)\n",
    "print \"More accurate when the float is .1 and less so when it's higher; time is faster than original regardless of float.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with subsample parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.0233918128655\n",
      "Time it takes to fit and predict XGB \t0.0179171562195\n",
      "More accurate when the float is .2 or .3 and less so when it's higher; time is faster than original regardless of float.\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier(subsample=.3)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)\n",
    "print \"More accurate when the float is .2 or .3 and less so when it's higher; time is faster than original regardless of float.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing XGBoost Classifier with the three fastest and most accurate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate is \t\t0.00584795321637\n",
      "Time it takes to fit and predict XGB \t0.00460195541382\n",
      "More accurate when the float is .2 or .3 and less so when it's higher; time is faster than original regardless of float.\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "XGB = XGBClassifier(n_estimators = 3, gamma = .1)#, subsample=.2)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate is \\t\\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))\n",
    "end = time.time()\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end - begin)\n",
    "print \"More accurate when the float is .2 or .3 and less so when it's higher; time is faster than original regardless of float.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most accurate parameters that took the least time were n_estimators (at int = 3), gamma (at float = .1), and subsample (at float = .2 or .3) individually. Together the accuracy decreases because of the subsample which is the ratio of the training instance. But if we just had n_estimators, and gamma, accuracy is higher and the time it takes is faster. This is because n_estimators is the number of trees boosted and gamma is the minimum loss reduction required to make a further partition on a leaf node of the tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparison's with Trees, Forests, and Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom inputs for XGB and old models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate for DTC is\t0.0760233918129\n",
      "The Misclassification rate for RFC is \t0.0526315789474\n",
      "The Misclassification rate for GBC is \t0.0526315789474\n",
      "The Misclassification rate for XGB is \t0.00584795321637\n",
      "\n",
      "Time it takes to fit and predict DTC\t0.00127696990967\n",
      "Time it takes to fit and predict RFC \t0.0217299461365\n",
      "Time it takes to fit and predict GBC \t0.0182859897614\n",
      "Time it takes to fit and predict XGB \t0.00263595581055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "begin0 = time.time()\n",
    "DTC = DecisionTreeClassifier(criterion = \"entropy\", splitter = \"random\")\n",
    "DTC.fit(X_train, Y_train)\n",
    "X_predict =  DTC.predict(X_test)\n",
    "print \"The Misclassification rate for DTC is\\t\" + str(sum((X_predict - Y_test)**2)/float(len(X_predict)))\n",
    "end0 = time.time()\n",
    "\n",
    "begin1 = time.time()\n",
    "RFC = RandomForestClassifier(criterion = \"entropy\", \n",
    "                             max_depth = 5)\n",
    "RFC.fit(X_train, Y_train)\n",
    "X_predict = RFC.predict(X_test)\n",
    "print \"The Misclassification rate for RFC is \\t\" + str(sum((X_predict - Y_test)**2)/float(len(X_predict)))\n",
    "end1 = time.time()\n",
    "\n",
    "begin2 = time.time()\n",
    "GBC = GradientBoostingClassifier(learning_rate = .9, n_estimators = 20, max_depth = 5)\n",
    "GBC.fit(X_train, Y_train)\n",
    "X_predict = GBC.predict(X_test)\n",
    "print \"The Misclassification rate for GBC is \\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict))) \n",
    "end2 = time.time()\n",
    "\n",
    "begin3 = time.time()\n",
    "XGB = XGBClassifier(n_estimators = 3, gamma = .1)#, subsample=.2)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate for XGB is \\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))+ \"\\n\"\n",
    "end3 = time.time()\n",
    "\n",
    "print \"Time it takes to fit and predict DTC\\t\" + str(end0 - begin0)\n",
    "print \"Time it takes to fit and predict RFC \\t\" + str(end1 - begin1)\n",
    "print \"Time it takes to fit and predict GBC \\t\" + str(end2 - begin2)\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end3 - begin3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The most accurate Classifier is the XGBoostClassifier, but the fastest is the DecisionTreeClassifier with XGBoost Classifier as a close second. So the one that has the best accuracy and the best time is XGBoostClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom inputs for XGB and default inputs for old models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Misclassification rate for DTC is\t0.0818713450292\n",
      "The Misclassification rate for RFC is \t0.0350877192982\n",
      "The Misclassification rate for GBC is \t0.0233918128655\n",
      "The Misclassification rate for XGB is \t0.00584795321637\n",
      "\n",
      "Time it takes to fit and predict DTC\t0.00353813171387\n",
      "Time it takes to fit and predict RFC \t0.0194439888\n",
      "Time it takes to fit and predict GBC \t0.0957210063934\n",
      "Time it takes to fit and predict XGB \t0.00243401527405\n"
     ]
    }
   ],
   "source": [
    "begin0 = time.time()\n",
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(X_train, Y_train)\n",
    "X_predict =  DTC.predict(X_test)\n",
    "print \"The Misclassification rate for DTC is\\t\" + str(sum((X_predict - Y_test)**2)/float(len(X_predict)))\n",
    "end0 = time.time()\n",
    "\n",
    "begin1 = time.time()\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(X_train, Y_train)\n",
    "X_predict = RFC.predict(X_test)\n",
    "print \"The Misclassification rate for RFC is \\t\" + str(sum((X_predict - Y_test)**2)/float(len(X_predict)))\n",
    "end1 = time.time()\n",
    "\n",
    "begin2 = time.time()\n",
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_train, Y_train)\n",
    "X_predict = GBC.predict(X_test)\n",
    "print \"The Misclassification rate for GBC is \\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict))) \n",
    "end2 = time.time()\n",
    "\n",
    "begin3 = time.time()\n",
    "XGB = XGBClassifier(n_estimators = 3, gamma = .1)\n",
    "XGB.fit(X_train, Y_train)\n",
    "X_predict = XGB.predict(X_test)\n",
    "print \"The Misclassification rate for XGB is \\t\" + str(sum(X_predict - Y_test)**2/float(len(X_predict)))+ \"\\n\"\n",
    "end3 = time.time()\n",
    "\n",
    "print \"Time it takes to fit and predict DTC\\t\" + str(end0 - begin0)\n",
    "print \"Time it takes to fit and predict RFC \\t\" + str(end1 - begin1)\n",
    "print \"Time it takes to fit and predict GBC \\t\" + str(end2 - begin2)\n",
    "print \"Time it takes to fit and predict XGB \\t\" + str(end3 - begin3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastest and most accurate classifier was XGBoostClassifier. XGBoost performed the best because it implements machine learning algorithms under the Gradient Boosting framework and provides a parallel tree boosting. It uses a more regularized model formalization to control over-fitting, which gives it better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
