{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import linalg as la\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import fmin_cg\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Mean Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading Continuous data set\n",
    "batch = 100\n",
    "data = datasets.load_boston()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "\n",
    "#making batch\n",
    "X_test = train_test_split(X, Y, test_size = batch)[1]\n",
    "Y_test = train_test_split(X, Y, test_size = batch)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implemented Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LR():\n",
    "    '''Linear Regression Class\n",
    "        Functions:  .pad - inserts a columns of ones to data set\n",
    "                    .fit - fitting the model according to the given training data\n",
    "                    .predict - predict class labels for samples in X\n",
    "    '''\n",
    "    def pad(self, X):\n",
    "        ''' Accepts: X - matrix, data\n",
    "            Returns: X - matrix, data, with a column of ones\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones(n).reshape(n,1), X))\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' Accepts: X - matrix, data\n",
    "                     Y - vector, label\n",
    "            Returns: w - vector, weights\n",
    "        '''\n",
    "        N = len(Y)\n",
    "        X = self.pad(X)\n",
    "        self.w = la.solve(np.dot(np.transpose(X), X), np.dot(np.transpose(X),Y))\n",
    "        SSE = np.sum((Y - np.dot(X, self.w))**2)\n",
    "        N = len(Y)\n",
    "        self.sigma = SSE/N\n",
    "        return self.w\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''Accepts: X - matrix, data\n",
    "           Returns: X.dot(w)\n",
    "        '''\n",
    "        return np.dot(self.pad(X), self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LMS():\n",
    "    '''Least Mean Squares\n",
    "        Functions:  .pad - inserts a columns of ones to data set\n",
    "                    .fit - fitting the model according to the given training data\n",
    "                    .predict - predict class labels for samples in X\n",
    "    '''\n",
    "    def pad(self, X):\n",
    "        ''' Accepts: X - matrix, data\n",
    "            Returns: X - matrix, data, with a column of ones\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        X = np.hstack((np.ones(n).reshape(n,1), X))\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, Y, tol, iters):\n",
    "        ''' Accepts: X - matrix, data\n",
    "                     Y - vector, label\n",
    "                     tol - float\n",
    "                     iters - int \n",
    "            Returns: w - vector, weights\n",
    "        '''\n",
    "        X = self.pad(X)\n",
    "        N, D  = X.shape\n",
    "        self.w = np.ones(D)\n",
    "        for i in range(N):\n",
    "            DQ = np.dot(X[i, :].T, np.dot(X[i, :],self.w) - Y[i])\n",
    "            eta_0 = 1./(1+i)\n",
    "            DQ = DQ/la.norm(DQ)\n",
    "            w_1 = (self.w - eta_0*DQ)\n",
    "            self.w = w_1\n",
    "        return self.w\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''Accepts: X - matrix, data\n",
    "           Returns: X.dot(w)\n",
    "        '''\n",
    "        return np.dot(self.pad(X), self.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timing Linear Regression and Least Mean Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.53312439e+00   2.00991937e+00   9.10052719e-02  -1.72940740e-01\n",
      "  -6.05507295e-03   3.75747451e+01   1.95548435e+01   1.74767622e+00\n",
      "  -3.52950123e+01  -7.59694578e+00  -6.44377709e+01   7.34092710e-02\n",
      "   2.91538972e-01   6.71728521e-01  -3.74363463e-02   1.04173285e+02\n",
      "  -1.02647144e+01   2.44995255e+01  -1.47259842e+02  -6.65924796e+00\n",
      "  -2.64835219e+02  -8.51979261e-01  -6.32137233e-02  -2.70945385e-02\n",
      "   7.28786724e-03  -1.28215134e+01  -6.20424348e-01  -6.10193333e-01\n",
      "   2.18022979e+01   3.15350066e+00  -8.40394245e+00]\n",
      "[-0.38341243 -0.01652866 -0.52502355]\n",
      "0.00500011444092\n",
      "[ 0.99586768  0.961372    0.92389559  0.74683281 -0.06480871  0.99958209\n",
      "  0.99935921  0.99943655  0.99983767  0.99909315  0.99966766  0.99845574\n",
      "  0.99332005  0.98805739  0.92149864  0.99996215  0.99980434  0.99970238\n",
      "  0.99992021  0.9998743   0.99997461  0.95744164  0.9043894   0.71691192\n",
      " -0.25489775  0.99946496  0.9987423   0.99859943  0.99960336  0.9987117\n",
      "  0.99959108]\n",
      "[-132.06245903 -214.5092016  -126.54622575]\n",
      "0.00699996948242\n"
     ]
    }
   ],
   "source": [
    "#Timing Implented Logistic Regression\n",
    "begin = time.time()\n",
    "m = LR()\n",
    "print m.fit(X_test, Y_test)\n",
    "print m.predict(X[0:3,:])\n",
    "end = time.time()\n",
    "diff = end-begin\n",
    "print diff\n",
    "\n",
    "#Timing Implemented Least Mean Squares\n",
    "begin1 = time.time()\n",
    "model = LMS()\n",
    "print model.fit(X_test,Y_test, .1, 100)\n",
    "print model.predict(X[0:3,:])\n",
    "end1 = time.time()\n",
    "diff1 = end1-begin1\n",
    "print diff1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loading Linearly Separable Data\n",
    "batch = 100\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "X_test = train_test_split(X, Y, test_size = batch)[1]\n",
    "Y_test = train_test_split(X, Y, test_size = batch)[3]\n",
    "\n",
    "#Changing 0's in Y to -1's\n",
    "Y_test1 = Y_test.copy()\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] == 0:\n",
    "        Y_test[i] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_reg(Lambda, X, Y):\n",
    "    '''Logistic Regression\n",
    "\n",
    "        Parameters: Lambda - postive float\n",
    "                    X      - matrix, data\n",
    "                    Y      - vector, binary\n",
    "        Returns:    w_hat  - vector, coefficient \n",
    "                            of the features in the \n",
    "                            decision function\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    X = np.hstack((np.ones(n).reshape(n,1), X))\n",
    "    N, D = X.shape\n",
    "\n",
    "    def sigm(w, x):\n",
    "        '''Sigmoid function\n",
    "            Parameters: w      - vector, weights\n",
    "                        x      - vector, data\n",
    "            Returns:    1/(1+e^(w^Tx))\n",
    "        '''\n",
    "        return 1./(1 + np.exp(-x.dot(w)))\n",
    "\n",
    "    def F(w):\n",
    "        '''Negative Log Likelihood Function\n",
    "            Parameters: w      - vector, initial guess\n",
    "            Returns:    w_hat  - vector, coefficient of \n",
    "                                the features in the \n",
    "                                decision functioon\n",
    "        '''\n",
    "        return np.sum(Y *np.log(1+np.exp(-X.dot(w))) + (1-Y)* np.log(np.exp(X.dot(w))+1))\n",
    "\n",
    "    #Using Newton's Method to find w_hat\n",
    "    w_hat = fmin_cg(F, np.zeros(D), disp = False)\n",
    "    \n",
    "    return w_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perceptron(X, Y):\n",
    "    '''Perceptron Algorithm\n",
    "        Accepts: X - matrix, data\n",
    "                 Y - vector, label\n",
    "        Returns: w_0 - vector, weights\n",
    "    '''\n",
    "    n = X.shape[0]\n",
    "    X = np.hstack((np.ones(n).reshape(n,1), X))\n",
    "    N, D  = X.shape\n",
    "    w_0 = np.ones(D)\n",
    "    for i in range(0, N):\n",
    "        eta = 1./(1+i)\n",
    "        y_hat = np.sign(np.dot(w_0, X[i, :]))\n",
    "        if y_hat != Y[i]:\n",
    "            w_0 = w_0 + Y[i]*X[i,:]*eta\n",
    "    return w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x, w):\n",
    "    '''Predict function for logistic regression (a.k.a. bias)\n",
    "        Parameters: x - vector, data\n",
    "                    w - vector, w_hat, or coefficients of the \n",
    "                        features of the decision function\n",
    "        Returns:    k - vector of true and false values\n",
    "    '''\n",
    "    def sigm(w, x):\n",
    "        '''Sigmoid function\n",
    "            Parameters: w      - vector, weights\n",
    "                        x      - vector, data\n",
    "            Returns:    1/(1+e^(w^Tx))\n",
    "        '''\n",
    "        return 1./(1 + np.exp(-x.dot(w)))\n",
    "    n = x.shape[0]\n",
    "    x = np.hstack((np.ones(n).reshape(n,1), x))\n",
    "    k = sigm(w, x)\n",
    "    return k >= .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Timing Perceptron with Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it take to fit perceptron is \t\t\t0.00200009346008\n",
      "Time it take to fit for Logisitic Regression Solver is \t0.233000040054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clmeha\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:14: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\clmeha\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:30: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\clmeha\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:30: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "#Timing Implemented Perceptron\n",
    "begin1 = time.time()\n",
    "w_hat = perceptron(X_test, Y_test)\n",
    "p = predict(X_test, w_hat)\n",
    "end1 = time.time()\n",
    "diff1 = end1 - begin1\n",
    "print \"Time it take to fit perceptron is \\t\\t\\t\" + str(diff1)\n",
    "\n",
    "#Timing Implemented Logistic Regression\n",
    "begin = time.time()\n",
    "w_hat_lr = logistic_reg(0, X_test, Y_test1)\n",
    "p1 = predict(X_test, w_hat_lr)\n",
    "end = time.time()\n",
    "diff = end- begin\n",
    "print \"Time it take to fit for Logisitic Regression Solver is \\t\" + str(diff)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
